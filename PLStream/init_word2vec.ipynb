{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4213a029",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from time import time\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "392ae0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "m=Word2Vec([['good']*10,['bad']*10],vector_size=20,alpha=0.03,min_count=10,min_alpha=0.0007,window=4,hs=1,sample=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2e7d598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec<vocab=2, vector_size=20, alpha=0.03>\n"
     ]
    }
   ],
   "source": [
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88212a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "init=Word2Vec.load('PLS_c10.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7558ba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x7f0639320b90>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59491881",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pd.read_csv('./yelp_review_polarity_csv/test.csv', header=None)  # , encoding='ISO-8859-1'\n",
    "f.columns = [\"label\", \"review\"]\n",
    "f.loc[f['label'] == 1, 'label'] = 0\n",
    "f.loc[f['label'] == 2, 'label'] = 1\n",
    "\n",
    "true_label = f.label\n",
    "yelp_review = f.review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f0c2da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 4.889155864715576\n",
      "[['contrary', 'reviews', 'zero', 'complaints', 'service', 'prices', 'getting', 'tire', 'service', 'past', 'years', 'now', 'compared', 'experience', 'places', 'like', 'pep', 'boys', 'guys', 'experienced', 'know', 'they', 're', 'doing', 'nalso', 'place', 'feel', 'like', 'taken', 'advantage', 'of', 'gender', 'other', 'auto', 'mechanics', 'notorious', 'capitalizing', 'ignorance', 'cars', 'sucked', 'bank', 'account', 'dry', 'but', 'here', 'service', 'road', 'coverage', 'explained', 'let', 'decide', 'nand', 'renovated', 'waiting', 'room', 'it', 'looks', 'lot', 'better', 'previous', 'years']]\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "import time\n",
    "start_time=time.time()\n",
    "clean_data=[remove_stopwords(review)for review in yelp_review]#remove frequent words that does not carry sentiment\n",
    "tokenised_data = [simple_preprocess(line, deacc=True) for line in clean_data] #remove punctuations and lowercase words also tokenise them\n",
    "print('time taken: '+str(time.time()-start_time))\n",
    "print(tokenised_data[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c52b20eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenised_data=pd.Series(tokenised_data,name='tokenised_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "949efe6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to train word2vec model: 33.177834033966064\n"
     ]
    }
   ],
   "source": [
    "# WARNING\n",
    "from gensim.models import Word2Vec\n",
    "# Skip-gram model (sg = 1)\n",
    "# size = 20\n",
    "# window = 3\n",
    "# min_count = 1\n",
    "# workers = 3\n",
    "\n",
    "\n",
    "vector_size=20\n",
    "alpha=0.03\n",
    "min_count=10\n",
    "min_alpha=0.0007\n",
    "window=4\n",
    "hs=1\n",
    "sample=0.00001\n",
    "epochs=30\n",
    "\n",
    "\n",
    "word2vec_model_file =  'word2vec' + str(vector_size) + 'tokenised.model'\n",
    "start_time = time()\n",
    "# Train the Word2Vec Model\n",
    "w2v_model = Word2Vec(tokenised_data, min_count = min_count, vector_size = vector_size, window = window, hs=hs,alpha=alpha,min_alpha=min_alpha,sample=sample,epochs=epochs)\n",
    "print(\"Time taken to train word2vec model: \" + str(time() - start_time))\n",
    "w2v_model.save(word2vec_model_file) # can be used by classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7be1f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_pos = ['love', 'best', 'beautiful', 'great', 'cool', 'awesome', 'wonderful', 'brilliant', 'excellent',\n",
    "                'fantastic']\n",
    "ref_neg = ['bad', 'worst', 'stupid', 'disappointing', 'terrible', 'rubbish', 'boring', 'awful',\n",
    "                'unwatchable', 'awkward']\n",
    "neg_coefficient=0.5\n",
    "pos_coefficient=0.5\n",
    "def predict(tweet,neg_coefficient,pos_coefficient, model,true_ref_neg=ref_neg,true_ref_pos=ref_pos,count=0,confidence=0.5):\n",
    "    sentence = np.zeros(model.vector_size)\n",
    "    counter = 0\n",
    "    cos_sim_bad, cos_sim_good = 0, 0\n",
    "    for words in tweet:\n",
    "        try:\n",
    "            sentence += model.wv[words]  # np.array(list(model.wv[words]) + new_feature)\n",
    "            counter += 1\n",
    "        except:\n",
    "            pass\n",
    "    if counter != 0:\n",
    "        sentence_vec = sentence / counter\n",
    "    k_cur = min(len(true_ref_neg), len(true_ref_pos))\n",
    "    for neg_word in true_ref_neg[:k_cur]:\n",
    "        try:\n",
    "            cos_sim_bad += np.dot(sentence_vec, model.wv[neg_word]) / (np.linalg.norm(sentence_vec) * np.linalg.norm(model.wv[neg_word]))\n",
    "        except:     \n",
    "            pass\n",
    "    for pos_word in true_ref_pos[:k_cur]:\n",
    "        try:\n",
    "            cos_sim_good += np.dot(sentence_vec, model.wv[pos_word]) / (np.linalg.norm(sentence_vec) * np.linalg.norm(model.wv[pos_word]))\n",
    "        except:\n",
    "            pass\n",
    "    if cos_sim_bad - cos_sim_good > confidence:\n",
    "        # while count<10:\n",
    "        #     print('in first if'+str(cos_sim_bad - cos_sim_good))\n",
    "        return  0\n",
    "    elif cos_sim_bad - cos_sim_good < -confidence:\n",
    "        return  1\n",
    "    else:\n",
    "        if cos_sim_bad * neg_coefficient >= cos_sim_good * pos_coefficient:\n",
    "            # if count<10:\n",
    "            #     print('in sec if'+str([cos_sim_bad,cos_sim_good,pos_coefficient,neg_coefficient]))\n",
    "            return  0\n",
    "        else:\n",
    "            return  1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "83ac3d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_result(tweets, neg_coefficient,pos_coefficient,w2v_mode,count=0):\n",
    "    predictions=[]\n",
    "    for t in range(len(tweets)):\n",
    "        predict_result = predict(tweets[t], neg_coefficient,pos_coefficient,w2v_model,count=count)\n",
    "        predictions.append(predict_result)\n",
    "        neg_coefficient = predictions.count(0) / (predictions.count(1) + predictions.count(0))\n",
    "        pos_coefficient = 1 - neg_coefficient\n",
    "        count += 1\n",
    "        \n",
    "    ans = accuracy_score(true_label, predictions)\n",
    "    # print(predictions.count(0))\n",
    "    # print(predictions.count(1))\n",
    "    # print(predictions[:10])\n",
    "    count += 1\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ee2cf63e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8180263157894737\n",
      "32.79794430732727\n",
      "vec size : 20 epochs : 30\n"
     ]
    }
   ],
   "source": [
    "start_time=time()\n",
    "\n",
    "print(classify_result(tokenised_data, neg_coefficient,pos_coefficient,w2v_model))\n",
    "print(time()-start_time)\n",
    "print(\"vec size : \"+str(vector_size),\"epochs : \"+str(epochs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c4d429",
   "metadata": {},
   "source": [
    "0.8180263157894737\n",
    "32.79794430732727\n",
    "vec size : 20 epochs : 300.8180263157894737\n",
    "32.79794430732727\n",
    "vec size : 20 epochs : 30\n",
    "\n",
    "\n",
    "0.823921052631579\n",
    "29.009666919708252\n",
    "vec size : 20 epochs : 60\n",
    "\n",
    "epoch 60 dim 90</br>\n",
    "0.8549736842105263</br>\n",
    "34.335697412490845</br>\n",
    "\n",
    "epoch 70 dim 90</br>\n",
    "0.856078947368421</br>\n",
    "30.640328407287598</br>\n",
    "\n",
    "epoch 80 dim 90</br>\n",
    "0.8548421052631578</br>\n",
    "27.404643297195435</br>\n",
    "\n",
    "epoch 90 dim 90</br>\n",
    "0.8538157894736842</br>\n",
    "31.939756870269775</br>\n",
    "\n",
    "epoch 90 dim 100</br>\n",
    "0.8587105263157895</br>\n",
    "32.94704008102417</br>\n",
    "\n",
    "epoch 100 dim 100</br>\n",
    "0.8558684210526316</br>\n",
    "29.760011911392212</br>\n",
    "\n",
    "epoch 110 dim 200</br>\n",
    "0.8533157894736842</br>\n",
    "36.04504609107971</br>\n",
    "\n",
    "epoch 100 dim 200 </br>\n",
    "0.8519473684210527</br>\n",
    "29.53914213180542</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "a32f1e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5b2b9365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38000"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(true_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "fb671fb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0827959 , -0.4999122 ,  1.3272713 ,  0.6675552 ,  0.1212782 ,\n",
       "       -0.52269405,  0.5355004 ,  0.18670893, -0.0178439 ,  0.80836487,\n",
       "        0.09435534, -1.005927  , -0.34542146, -0.6518756 ,  0.3240503 ,\n",
       "        0.5868083 ,  0.30133593, -0.613059  , -0.59222174, -0.67930746],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv['awful']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8806b9",
   "metadata": {},
   "source": [
    "### Test PLStream accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2b1d8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 104.03294658660889\n",
      "[['unfortunately', 'frustration', 'dr', 'goldberg', 'patient', 'repeat', 'experience', 've', 'doctors', 'nyc', 'good', 'doctor', 'terrible', 'staff', 'it', 'staff', 'simply', 'answers', 'phone', 'it', 'usually', 'takes', 'hours', 'repeated', 'calling', 'answer', 'who', 'time', 'wants', 'deal', 'it', 'run', 'problem', 'doctors', 'don', 'it', 'you', 'office', 'workers', 'patients', 'medical', 'needs', 'isn', 'answering', 'phone', 'it', 'work', 'aggravation', 'it', 'regret', 'feel', 'dr', 'goldberg', 'stars']]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from time import time\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "\n",
    "# f = pd.read_csv('./yelp_review_polarity_csv/test.csv', header=None)  # , encoding='ISO-8859-1'\n",
    "f = pd.read_csv('train.csv', header=None)  # , encoding='ISO-8859-1'\n",
    "f.columns = [\"label\", \"review\"]\n",
    "f.loc[f['label'] == 1, 'label'] = 0\n",
    "f.loc[f['label'] == 2, 'label'] = 1\n",
    "\n",
    "true_label = f.label\n",
    "yelp_review = f.review\n",
    "\n",
    "start_time=time()\n",
    "clean_data=[remove_stopwords(review)for review in yelp_review]#remove frequent words that does not carry sentiment\n",
    "tokenised_data = [simple_preprocess(line, deacc=True) for line in clean_data] #remove punctuations and lowercase words also tokenise them\n",
    "print('time taken: '+str(time()-start_time))\n",
    "print(tokenised_data[:1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e97258e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "560000\n",
      "0.7495\n",
      "0.7635\n",
      "0.792\n",
      "0.8\n",
      "0.7895\n",
      "0.7565\n",
      "0.808\n",
      "0.829\n",
      "0.8315\n",
      "0.823\n",
      "0.7885\n",
      "0.78\n",
      "0.749\n",
      "0.8185\n",
      "0.7995\n",
      "0.7515\n",
      "0.806\n",
      "0.7575\n",
      "0.8145\n",
      "0.8105\n",
      "0.817\n",
      "0.774\n",
      "0.788\n",
      "0.8325\n",
      "0.8165\n",
      "0.833\n",
      "0.8475\n",
      "0.8305\n",
      "0.8445\n",
      "0.819\n",
      "0.8395\n",
      "0.8085\n",
      "0.7455\n",
      "0.7085\n",
      "0.7355\n",
      "0.796\n",
      "0.808\n",
      "0.7565\n",
      "0.8175\n",
      "0.812\n",
      "0.782\n",
      "0.8165\n",
      "0.818\n",
      "0.835\n",
      "0.787\n",
      "0.826\n",
      "0.7805\n",
      "0.8385\n",
      "0.787\n",
      "0.792\n",
      "0.8125\n",
      "0.709\n",
      "0.798\n",
      "0.828\n",
      "0.776\n",
      "0.802\n",
      "0.8335\n",
      "0.7825\n",
      "0.721\n",
      "0.7975\n",
      "0.7965\n",
      "0.7805\n",
      "0.79\n",
      "0.788\n",
      "0.795\n",
      "0.687\n",
      "0.7075\n",
      "0.744\n",
      "0.7445\n",
      "0.835\n",
      "0.765\n",
      "0.805\n",
      "0.799\n",
      "0.84\n",
      "0.743\n",
      "0.7835\n",
      "0.7095\n",
      "0.712\n",
      "0.782\n",
      "0.77\n",
      "0.796\n",
      "0.786\n",
      "0.79\n",
      "0.771\n",
      "0.773\n",
      "0.772\n",
      "0.821\n",
      "0.8055\n",
      "0.788\n",
      "0.7745\n",
      "0.7645\n",
      "0.809\n",
      "0.7895\n",
      "0.802\n",
      "0.7565\n",
      "0.8305\n",
      "0.841\n",
      "0.8265\n",
      "0.7765\n",
      "0.793\n",
      "0.8085\n",
      "0.773\n",
      "0.809\n",
      "0.794\n",
      "0.802\n",
      "0.801\n",
      "0.8125\n",
      "0.8075\n",
      "0.822\n",
      "0.804\n",
      "0.7855\n",
      "0.8135\n",
      "0.7645\n",
      "0.7715\n",
      "0.7735\n",
      "0.758\n",
      "0.761\n",
      "0.792\n",
      "0.7515\n",
      "0.815\n",
      "0.815\n",
      "0.805\n",
      "0.811\n",
      "0.7835\n",
      "0.792\n",
      "0.795\n",
      "0.8355\n",
      "0.8315\n",
      "0.8095\n",
      "0.7895\n",
      "0.801\n",
      "0.7905\n",
      "0.775\n",
      "0.8025\n",
      "0.805\n",
      "0.8\n",
      "0.826\n",
      "0.7955\n",
      "0.7725\n",
      "0.788\n",
      "0.794\n",
      "0.795\n",
      "0.791\n",
      "0.741\n",
      "0.7945\n",
      "0.7755\n",
      "0.8375\n",
      "0.791\n",
      "0.8125\n",
      "0.7925\n",
      "0.7325\n",
      "0.797\n",
      "0.82\n",
      "0.814\n",
      "0.7985\n",
      "0.7325\n",
      "0.8565\n",
      "0.827\n",
      "0.8365\n",
      "0.712\n",
      "0.8145\n",
      "0.8065\n",
      "0.7975\n",
      "0.8415\n",
      "0.8195\n",
      "0.7825\n",
      "0.6565\n",
      "0.681\n",
      "0.766\n",
      "0.801\n",
      "0.794\n",
      "0.772\n",
      "0.7945\n",
      "0.82\n",
      "0.813\n",
      "0.783\n",
      "0.822\n",
      "0.8035\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_88996/1705247699.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m     m.train(new_sentences,  # 2) incremental training\n\u001b[1;32m     23\u001b[0m                               \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                               epochs=m.epochs)\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;31m#     m = Word2Vec(tokenised_data, min_count = min_count, vector_size = vector_size, window = window, hs=hs,alpha=alpha,min_alpha=min_alpha,sample=sample,epochs=epochs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/SentiStream/PLStream/venv/lib/python3.7/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, corpus_iterable, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m   1071\u001b[0m                     \u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcur_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m                     \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mqueue_factor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport_delay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreport_delay\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1073\u001b[0;31m                     callbacks=callbacks, **kwargs)\n\u001b[0m\u001b[1;32m   1074\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m                 trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch = self._train_epoch_corpusfile(\n",
      "\u001b[0;32m~/Desktop/SentiStream/PLStream/venv/lib/python3.7/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36m_train_epoch\u001b[0;34m(self, data_iterable, cur_epoch, total_examples, total_words, queue_factor, report_delay, callbacks)\u001b[0m\n\u001b[1;32m   1431\u001b[0m         trained_word_count, raw_word_count, job_tally = self._log_epoch_progress(\n\u001b[1;32m   1432\u001b[0m             \u001b[0mprogress_queue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_queue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcur_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1433\u001b[0;31m             \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport_delay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreport_delay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_corpus_file_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1434\u001b[0m         )\n\u001b[1;32m   1435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/SentiStream/PLStream/venv/lib/python3.7/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36m_log_epoch_progress\u001b[0;34m(self, progress_queue, job_queue, cur_epoch, total_examples, total_words, report_delay, is_corpus_file_mode)\u001b[0m\n\u001b[1;32m   1284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0munfinished_worker_count\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1286\u001b[0;31m             \u001b[0mreport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprogress_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# blocks if workers too slow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1287\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreport\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# a thread reporting that it finished\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m                 \u001b[0munfinished_worker_count\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.13/lib/python3.7/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.13/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "m=Word2Vec([['good']*10,['bad']*10],vector_size=20,alpha=0.03,min_count=10,min_alpha=0.0007,window=4,hs=1,sample=0.00001,epochs=90)\n",
    "\n",
    "\n",
    "vector_size=100\n",
    "alpha=0.03\n",
    "min_count=10\n",
    "min_alpha=0.0007\n",
    "window=4\n",
    "hs=1\n",
    "sample=0.00001\n",
    "epochs=60\n",
    "\n",
    "collector_size=2000\n",
    "print(len(tokenised_data))\n",
    "start=time()\n",
    "for i in range(0,len(tokenised_data),collector_size):\n",
    "    \n",
    "    new_sentences=tokenised_data[i:collector_size+i]\n",
    "    labels=true_label[i:collector_size+i]\n",
    "    \n",
    "    m.build_vocab(new_sentences, update=True)  # 1) update vocabulary\n",
    "    m.train(new_sentences,  # 2) incremental training\n",
    "                              total_examples=m.corpus_count,\n",
    "                              epochs=m.epochs)\n",
    "#     m = Word2Vec(tokenised_data, min_count = min_count, vector_size = vector_size, window = window, hs=hs,alpha=alpha,min_alpha=min_alpha,sample=sample,epochs=epochs)\n",
    "\n",
    "    predictions=[]\n",
    "    for sen in new_sentences:\n",
    "        predict_result = predict(sen, neg_coefficient,pos_coefficient,m)\n",
    "        predictions.append(predict_result)\n",
    "        neg_coefficient = predictions.count(0) / (predictions.count(1) + predictions.count(0))\n",
    "        pos_coefficient = 1 - neg_coefficient\n",
    "        \n",
    "    ans = accuracy_score(labels, predictions)\n",
    "    # print(predictions.count(0))\n",
    "    # print(predictions.count(1))\n",
    "    # print(predictions[:10])\n",
    "    print(ans)\n",
    "print(\"time taken: \"+str(time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a897c10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
